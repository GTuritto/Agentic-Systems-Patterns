# Adversarial Testing Agent Pattern

Description: “Red team” agent that attempts to mislead or break another agent to test robustness.

Value: Improves resilience and compliance of deployed agents.

## Deliverables

- Adversarial interaction diagram
- Vulnerability report generation
- Example with safe prompt injection attempts

## Notes

- Include allowlist/denylist checks and safe sandboxes for tool calls.
- Report should summarize tested vectors and outcomes.
